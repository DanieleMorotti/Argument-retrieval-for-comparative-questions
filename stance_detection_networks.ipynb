{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaf7ac58-6b1d-4a86-a9a9-7aa225befd02",
   "metadata": {
    "id": "aaf7ac58-6b1d-4a86-a9a9-7aa225befd02",
    "tags": []
   },
   "source": [
    "### Stance detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3200f066-4d6f-40d2-acbe-7436e3a31465",
   "metadata": {
    "id": "3200f066-4d6f-40d2-acbe-7436e3a31465"
   },
   "source": [
    "### Stance detection for comparative question is the task consisting of determining, given a comparative question $Q$ between two objects $O_1$ and $O_2$ and an answer $A$, the stance of $A$ with respect to Q. The answer can either express:\n",
    "- No stance;\n",
    "- Neutrality;\n",
    "- Being in favour of $O_1$;\n",
    "- Being in favour of $O_2$.\n",
    "### The paper \"[LeviRANK: Limited Query Expansion with Voting Integration for Document Retrieval and Ranking](https://ceur-ws.org/Vol-3180/paper-259.pdf)\" provides some results according to which, by splitting the task above in the two sub-tasks consisting of initially determining whether the stance is \"No stance\", \"Neutrality\" or \"Being in favour of $O_x$\" ($x \\in \\{1,2\\}$) and then, if the last evaluation yielded \"Being in favour of $O_x$\", determining whether $x$ is $1$ or $2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13740635-ed1f-4417-ab3c-d367e1d08325",
   "metadata": {
    "id": "13740635-ed1f-4417-ab3c-d367e1d08325"
   },
   "source": [
    "# librerie usate: unire con quelle del notebook principale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "LDhS9y7VFBQK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LDhS9y7VFBQK",
    "outputId": "e18e0b1a-c145-4deb-d445-e414858afbb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\andrea\\anaconda3\\lib\\site-packages (4.24.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: requests in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\andrea\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e949c0da-16e8-473e-9697-a509c432b8fd",
   "metadata": {
    "id": "e949c0da-16e8-473e-9697-a509c432b8fd"
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f04c2bfe-a62d-4ee8-8395-2b31321a045f",
   "metadata": {
    "id": "f04c2bfe-a62d-4ee8-8395-2b31321a045f"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class StanceConfig:\n",
    "    DATASET_PATH = 'touche22-task2-stance-dataset.tsv'\n",
    "    INIT_LR = 1e-5\n",
    "    LR_REDUCTION_FACTOR_PLATEAU = .1\n",
    "    MIN_LR = 1e-8\n",
    "    MODEL_NNO_BATCH_SIZE = 16\n",
    "    MODEL_OBJ_BATCH_SIZE = 16\n",
    "    MODEL_NNO_CHECKPOINT_FOLDER = './model_nno_checkpoint/'\n",
    "    MODEL_OBJ_CHECKPOINT_FOLDER = './model_obj_checkpoint/'\n",
    "    MODEL_NNO_EPOCHS = 150\n",
    "    MODEL_OBJ_EPOCHS = 150\n",
    "    SEED = 42\n",
    "    TRAIN_VAL_TEST_RATIOS = {'train': .8, 'val': .1, 'test': .1}\n",
    "\n",
    "stance_config = StanceConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919c0055-145c-4354-9631-79af68d5c058",
   "metadata": {
    "id": "919c0055-145c-4354-9631-79af68d5c058"
   },
   "source": [
    "#### Lettura del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ed53a6c7-8195-404f-bed0-70691c4fd796",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 745
    },
    "id": "ed53a6c7-8195-404f-bed0-70691c4fd796",
    "outputId": "6c33ffe6-ebad-44e3-b94a-615c7231eadc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_stance</th>\n",
       "      <th>answer_stance_object</th>\n",
       "      <th>object_count</th>\n",
       "      <th>object_1</th>\n",
       "      <th>mask_pos_1</th>\n",
       "      <th>object_2</th>\n",
       "      <th>mask_pos_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>softwareengineering.stackexchange</td>\n",
       "      <td>10373</td>\n",
       "      <td>What's the better way to charge for a cloud pl...</td>\n",
       "      <td>Like all good questions, the answer depends. I...</td>\n",
       "      <td>2</td>\n",
       "      <td>simple but more expensive</td>\n",
       "      <td>2</td>\n",
       "      <td>simple but more expensive</td>\n",
       "      <td>[[231, 252], [389, 393], [605, 619], [753, 757]]</td>\n",
       "      <td>complicated but cheaper</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>softwareengineering.stackexchange</td>\n",
       "      <td>18838</td>\n",
       "      <td>Haskell AND Lisp vs. Haskell OR Lisp</td>\n",
       "      <td>I suggest learning both, Haskell first, then C...</td>\n",
       "      <td>2</td>\n",
       "      <td>Haskell AND Lisp</td>\n",
       "      <td>2</td>\n",
       "      <td>Haskell AND Lisp</td>\n",
       "      <td>[[25, 56]]</td>\n",
       "      <td>Haskell OR Lisp</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>softwareengineering.stackexchange</td>\n",
       "      <td>19392</td>\n",
       "      <td>When is it better to offload work to the RDBMS...</td>\n",
       "      <td>You want to do all set-based operations in the...</td>\n",
       "      <td>3</td>\n",
       "      <td>do it in code</td>\n",
       "      <td>2</td>\n",
       "      <td>offload work to the RDBMS</td>\n",
       "      <td>[[40, 55], [232, 248]]</td>\n",
       "      <td>do it in code</td>\n",
       "      <td>[[165, 175], [578, 598]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>softwareengineering.stackexchange</td>\n",
       "      <td>20653</td>\n",
       "      <td>Is it better to specialize in a single field I...</td>\n",
       "      <td>Specialise if you enjoy it  As you are aware, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>expand into other fields to broaden my horizons</td>\n",
       "      <td>2</td>\n",
       "      <td>to specialize in a single field I like</td>\n",
       "      <td>[[53, 63], [404, 410], [512, 519]]</td>\n",
       "      <td>expand into other fields to broaden my horizons</td>\n",
       "      <td>[[892, 933]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>softwareengineering.stackexchange</td>\n",
       "      <td>21186</td>\n",
       "      <td>Microsoft SDE Interview vs Microsoft SDET Inte...</td>\n",
       "      <td>Unfortunately, those are both myths. SDEs and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>Microsoft SDE Interview</td>\n",
       "      <td>[[37, 41], [283, 295], [950, 962]]</td>\n",
       "      <td>Microsoft SDET Interview</td>\n",
       "      <td>[[46, 51], [341, 354], [832, 836], [938, 945]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  ds     id  \\\n",
       "0  softwareengineering.stackexchange  10373   \n",
       "1  softwareengineering.stackexchange  18838   \n",
       "2  softwareengineering.stackexchange  19392   \n",
       "3  softwareengineering.stackexchange  20653   \n",
       "4  softwareengineering.stackexchange  21186   \n",
       "\n",
       "                                            question  \\\n",
       "0  What's the better way to charge for a cloud pl...   \n",
       "1               Haskell AND Lisp vs. Haskell OR Lisp   \n",
       "2  When is it better to offload work to the RDBMS...   \n",
       "3  Is it better to specialize in a single field I...   \n",
       "4  Microsoft SDE Interview vs Microsoft SDET Inte...   \n",
       "\n",
       "                                              answer  answer_stance  \\\n",
       "0  Like all good questions, the answer depends. I...              2   \n",
       "1  I suggest learning both, Haskell first, then C...              2   \n",
       "2  You want to do all set-based operations in the...              3   \n",
       "3  Specialise if you enjoy it  As you are aware, ...              3   \n",
       "4  Unfortunately, those are both myths. SDEs and ...              1   \n",
       "\n",
       "                              answer_stance_object  object_count  \\\n",
       "0                        simple but more expensive             2   \n",
       "1                                 Haskell AND Lisp             2   \n",
       "2                                    do it in code             2   \n",
       "3  expand into other fields to broaden my horizons             2   \n",
       "4                                          Neutral             2   \n",
       "\n",
       "                                 object_1  \\\n",
       "0               simple but more expensive   \n",
       "1                        Haskell AND Lisp   \n",
       "2               offload work to the RDBMS   \n",
       "3  to specialize in a single field I like   \n",
       "4                 Microsoft SDE Interview   \n",
       "\n",
       "                                         mask_pos_1  \\\n",
       "0  [[231, 252], [389, 393], [605, 619], [753, 757]]   \n",
       "1                                        [[25, 56]]   \n",
       "2                            [[40, 55], [232, 248]]   \n",
       "3                [[53, 63], [404, 410], [512, 519]]   \n",
       "4                [[37, 41], [283, 295], [950, 962]]   \n",
       "\n",
       "                                          object_2  \\\n",
       "0                          complicated but cheaper   \n",
       "1                                  Haskell OR Lisp   \n",
       "2                                    do it in code   \n",
       "3  expand into other fields to broaden my horizons   \n",
       "4                         Microsoft SDET Interview   \n",
       "\n",
       "                                       mask_pos_2  \n",
       "0                                              []  \n",
       "1                                              []  \n",
       "2                        [[165, 175], [578, 598]]  \n",
       "3                                    [[892, 933]]  \n",
       "4  [[46, 51], [341, 354], [832, 836], [938, 945]]  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(stance_config.DATASET_PATH, sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65233553-cfcd-4976-b1a5-c0169ad23c1e",
   "metadata": {
    "id": "65233553-cfcd-4976-b1a5-c0169ad23c1e"
   },
   "source": [
    "#### For the current task, only the columns \"question\", \"answer\" and \"answer_stance\" are needed, since the aim of this section is to build a model able to tell the stance of the answer with respect to the asked question, as described. We also include the \"dataset\" column in order to be sure that we're hiding (as per license conditions) the records coming from the dataset kindly provided by Yahoo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d9b56ad-34e5-490a-9ae4-612e86777f69",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "9d9b56ad-34e5-490a-9ae4-612e86777f69",
    "outputId": "8136acb1-f062-446c-fb17-38c32d1f63a2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>softwareengineering.stackexchange</td>\n",
       "      <td>What's the better way to charge for a cloud pl...</td>\n",
       "      <td>Like all good questions, the answer depends. I...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>softwareengineering.stackexchange</td>\n",
       "      <td>Haskell AND Lisp vs. Haskell OR Lisp</td>\n",
       "      <td>I suggest learning both, Haskell first, then C...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>softwareengineering.stackexchange</td>\n",
       "      <td>When is it better to offload work to the RDBMS...</td>\n",
       "      <td>You want to do all set-based operations in the...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>softwareengineering.stackexchange</td>\n",
       "      <td>Is it better to specialize in a single field I...</td>\n",
       "      <td>Specialise if you enjoy it  As you are aware, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>softwareengineering.stackexchange</td>\n",
       "      <td>Microsoft SDE Interview vs Microsoft SDET Inte...</td>\n",
       "      <td>Unfortunately, those are both myths. SDEs and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  ds  \\\n",
       "0  softwareengineering.stackexchange   \n",
       "1  softwareengineering.stackexchange   \n",
       "2  softwareengineering.stackexchange   \n",
       "3  softwareengineering.stackexchange   \n",
       "4  softwareengineering.stackexchange   \n",
       "\n",
       "                                            question  \\\n",
       "0  What's the better way to charge for a cloud pl...   \n",
       "1               Haskell AND Lisp vs. Haskell OR Lisp   \n",
       "2  When is it better to offload work to the RDBMS...   \n",
       "3  Is it better to specialize in a single field I...   \n",
       "4  Microsoft SDE Interview vs Microsoft SDET Inte...   \n",
       "\n",
       "                                              answer  answer_stance  \n",
       "0  Like all good questions, the answer depends. I...              2  \n",
       "1  I suggest learning both, Haskell first, then C...              2  \n",
       "2  You want to do all set-based operations in the...              3  \n",
       "3  Specialise if you enjoy it  As you are aware, ...              3  \n",
       "4  Unfortunately, those are both myths. SDEs and ...              1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.loc[:, ['ds','question','answer','answer_stance']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75439883-e131-4680-84de-5c5c64944f44",
   "metadata": {
    "id": "75439883-e131-4680-84de-5c5c64944f44"
   },
   "source": [
    "#### Now, we'll derive two dataset from this one:\n",
    "- `df_nno`: used to train a network focused on determining whether the stance is \"No stance\", \"Neutrality\" or \"Being in favour of $O_x$\" ($x \\in \\{1,2\\}$);\n",
    "- `df_obj`: used to train a network focused on determining whether the stance is \"Being in favour of $O_1$\" or \"Being in favour of $O_2$\".\n",
    "#### In particular, the first dataset will remove the distinction between `answer_stance` being equal to $2$ or $3$, the second dataset will consider ONLY the pairs (`question`, `answer`) whose `answer_stance` is either $2$ or $3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "521523d9-4bd7-406c-85a6-fd2dec4084f5",
   "metadata": {
    "id": "521523d9-4bd7-406c-85a6-fd2dec4084f5"
   },
   "outputs": [],
   "source": [
    "df_nno = df.copy()\n",
    "df_obj = df.copy()\n",
    "\n",
    "#The answer stances \"Being in favour of O_1/2\" must become indistinguishable from each other.\n",
    "df_nno.loc[df_nno.answer_stance == 3, 'answer_stance'] = 2\n",
    "\n",
    "#The only answer stances that we're considering are \"Being in favour of O_1/2\".\n",
    "df_obj = df_obj.loc[df_obj.answer_stance.isin([2,3]),:]\n",
    "\n",
    "#Remapping the answer stances \"2\" and \"3\" to, respectively, \"0\" and \"1\"\n",
    "df_obj.answer_stance -= 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf33b5aa-f4f5-4cef-8613-cc98c4d36d04",
   "metadata": {
    "id": "cf33b5aa-f4f5-4cef-8613-cc98c4d36d04"
   },
   "source": [
    "#### Viewing the resulting DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6332ecb9-4729-49f6-a709-e4e3997ea175",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6332ecb9-4729-49f6-a709-e4e3997ea175",
    "outputId": "e14f03aa-ac61-41b4-bdcf-724f314aea0e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>softwareengineering.stackexchange</td>\n",
       "      <td>What's the better way to charge for a cloud pl...</td>\n",
       "      <td>Like all good questions, the answer depends. I...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>softwareengineering.stackexchange</td>\n",
       "      <td>Haskell AND Lisp vs. Haskell OR Lisp</td>\n",
       "      <td>I suggest learning both, Haskell first, then C...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>softwareengineering.stackexchange</td>\n",
       "      <td>When is it better to offload work to the RDBMS...</td>\n",
       "      <td>You want to do all set-based operations in the...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>softwareengineering.stackexchange</td>\n",
       "      <td>Is it better to specialize in a single field I...</td>\n",
       "      <td>Specialise if you enjoy it  As you are aware, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>softwareengineering.stackexchange</td>\n",
       "      <td>Microsoft SDE Interview vs Microsoft SDET Inte...</td>\n",
       "      <td>Unfortunately, those are both myths. SDEs and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  ds  \\\n",
       "0  softwareengineering.stackexchange   \n",
       "1  softwareengineering.stackexchange   \n",
       "2  softwareengineering.stackexchange   \n",
       "3  softwareengineering.stackexchange   \n",
       "4  softwareengineering.stackexchange   \n",
       "\n",
       "                                            question  \\\n",
       "0  What's the better way to charge for a cloud pl...   \n",
       "1               Haskell AND Lisp vs. Haskell OR Lisp   \n",
       "2  When is it better to offload work to the RDBMS...   \n",
       "3  Is it better to specialize in a single field I...   \n",
       "4  Microsoft SDE Interview vs Microsoft SDET Inte...   \n",
       "\n",
       "                                              answer  answer_stance  \n",
       "0  Like all good questions, the answer depends. I...              2  \n",
       "1  I suggest learning both, Haskell first, then C...              2  \n",
       "2  You want to do all set-based operations in the...              2  \n",
       "3  Specialise if you enjoy it  As you are aware, ...              2  \n",
       "4  Unfortunately, those are both myths. SDEs and ...              1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f1f7e70-c2ce-4169-863f-31ffd1fec261",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "9f1f7e70-c2ce-4169-863f-31ffd1fec261",
    "outputId": "bf73c937-fe46-4365-e77f-d6ec6a3d0721"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>softwareengineering.stackexchange</td>\n",
       "      <td>What's the better way to charge for a cloud pl...</td>\n",
       "      <td>Like all good questions, the answer depends. I...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>softwareengineering.stackexchange</td>\n",
       "      <td>Haskell AND Lisp vs. Haskell OR Lisp</td>\n",
       "      <td>I suggest learning both, Haskell first, then C...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>softwareengineering.stackexchange</td>\n",
       "      <td>When is it better to offload work to the RDBMS...</td>\n",
       "      <td>You want to do all set-based operations in the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>softwareengineering.stackexchange</td>\n",
       "      <td>Is it better to specialize in a single field I...</td>\n",
       "      <td>Specialise if you enjoy it  As you are aware, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>softwareengineering.stackexchange</td>\n",
       "      <td>How is IntelliJ better than Eclipse?</td>\n",
       "      <td>I work with Intellij (9.0.4 Ultimate) and Ecli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  ds  \\\n",
       "0  softwareengineering.stackexchange   \n",
       "1  softwareengineering.stackexchange   \n",
       "2  softwareengineering.stackexchange   \n",
       "3  softwareengineering.stackexchange   \n",
       "5  softwareengineering.stackexchange   \n",
       "\n",
       "                                            question  \\\n",
       "0  What's the better way to charge for a cloud pl...   \n",
       "1               Haskell AND Lisp vs. Haskell OR Lisp   \n",
       "2  When is it better to offload work to the RDBMS...   \n",
       "3  Is it better to specialize in a single field I...   \n",
       "5               How is IntelliJ better than Eclipse?   \n",
       "\n",
       "                                              answer  answer_stance  \n",
       "0  Like all good questions, the answer depends. I...              0  \n",
       "1  I suggest learning both, Haskell first, then C...              0  \n",
       "2  You want to do all set-based operations in the...              1  \n",
       "3  Specialise if you enjoy it  As you are aware, ...              1  \n",
       "5  I work with Intellij (9.0.4 Ultimate) and Ecli...              0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_obj.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3678186-06f9-436d-8865-e2d41ccd9ba4",
   "metadata": {
    "id": "a3678186-06f9-436d-8865-e2d41ccd9ba4"
   },
   "source": [
    "#### Building the networks:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfda394c-0c78-443f-8dd5-48695b9628ee",
   "metadata": {
    "id": "cfda394c-0c78-443f-8dd5-48695b9628ee"
   },
   "source": [
    "#### According to the aforementioned paper, a fine-tuned version of the *RoBERTA-Large-MNLI* is appropriate for the task of stance detection. For this reason, we chose to use a lighter model, originally fine-tuned on the same dataset: *distilbert-base-uncased-mnli* ([typeform/distilbert-base-uncased-mnli · Hugging Face](https://huggingface.co/typeform/distilbert-base-uncased-mnli)). Since the tasks are similar, but different, we load two variations of the previously hinted model, whose difference is just the head of the networks (some `Dense` layers that act as \"Classification\" layers), \"re-assembled\" in order to output either $2$ or $3$ values, depending on the number of needed classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52edc14d-f707-464b-afa3-4f2b285266f6",
   "metadata": {
    "id": "52edc14d-f707-464b-afa3-4f2b285266f6"
   },
   "source": [
    "#### Retrieving the tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fb6ec4a-6965-401e-bf7f-6ca57449f7d2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8fb6ec4a-6965-401e-bf7f-6ca57449f7d2",
    "outputId": "56a4cfd8-cc5d-4b63-94fe-54af060c9102"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da96bbafb8e945d2bad2705dd315c25b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrea\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:123: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Andrea\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b24681fd534cc1aa6f5d09fefccbe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961ae39ce8af4cad9608503066759245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/258 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f34584f6b82d4b3f885a09ec8bc5bc67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/776 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(\"typeform/distilbert-base-uncased-mnli\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a037363-ae24-4500-a72e-0d0227691033",
   "metadata": {
    "id": "2a037363-ae24-4500-a72e-0d0227691033"
   },
   "source": [
    "#### Retrieving the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2142398f-76a8-4383-9411-b2a661d64418",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2142398f-76a8-4383-9411-b2a661d64418",
    "outputId": "9d683b99-d9a4-4176-ecb3-3d76929fcfde"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e119d983546d442a93bd55cbeb19bd96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at typeform/distilbert-base-uncased-mnli.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some layers from the model checkpoint at typeform/distilbert-base-uncased-mnli were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at typeform/distilbert-base-uncased-mnli and are newly initialized: ['dropout_39']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at typeform/distilbert-base-uncased-mnli and are newly initialized because the shapes did not match:\n",
      "- classifier/kernel:0: found shape (768, 3) in the checkpoint and (768, 2) in the model instantiated\n",
      "- classifier/bias:0: found shape (3,) in the checkpoint and (2,) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_nno = TFDistilBertForSequenceClassification.from_pretrained(\"typeform/distilbert-base-uncased-mnli\", num_labels=3)\n",
    "model_obj = TFDistilBertForSequenceClassification.from_pretrained(\"typeform/distilbert-base-uncased-mnli\", num_labels=2, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d04419-def4-47a4-ba94-d8e3fd62526f",
   "metadata": {
    "id": "62d04419-def4-47a4-ba94-d8e3fd62526f"
   },
   "source": [
    "#### Looking at the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18357869-d9c2-4fab-b6fd-79c47a096251",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "18357869-d9c2-4fab-b6fd-79c47a096251",
    "outputId": "d8361606-bc55-41a7-f72c-d008d55698cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " distilbert (TFDistilBertMai  multiple                 66362880  \n",
      " nLayer)                                                         \n",
      "                                                                 \n",
      " pre_classifier (Dense)      multiple                  590592    \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  2307      \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,955,779\n",
      "Trainable params: 66,955,779\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"tf_distil_bert_for_sequence_classification_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " distilbert (TFDistilBertMai  multiple                 66362880  \n",
      " nLayer)                                                         \n",
      "                                                                 \n",
      " pre_classifier (Dense)      multiple                  590592    \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,955,010\n",
      "Trainable params: 66,955,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_nno.summary()\n",
    "model_obj.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8e7c94-6a6d-4522-bfbd-562bd493c424",
   "metadata": {
    "id": "1c8e7c94-6a6d-4522-bfbd-562bd493c424"
   },
   "source": [
    "#### We want to fine-tune the model, therefore we freeze the part of the network responsible of taking care of the *encoding* part of the process, and then we compile them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285e9106-c344-4596-a31c-19c66b368d42",
   "metadata": {
    "id": "285e9106-c344-4596-a31c-19c66b368d42"
   },
   "source": [
    "#### Compiling the networks to prepare them for training (fine-tuning):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2502a93f-3f5d-4d4f-a0c8-6222c2ad168c",
   "metadata": {
    "id": "2502a93f-3f5d-4d4f-a0c8-6222c2ad168c"
   },
   "outputs": [],
   "source": [
    "for model in [model_nno, model_obj]:\n",
    "    model.distilbert.trainable = False\n",
    "    model.compile(\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate = stance_config.INIT_LR),\n",
    "        metrics=keras.metrics.SparseCategoricalAccuracy()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cea517-bec8-43cf-8b86-1861fc3a2622",
   "metadata": {
    "id": "01cea517-bec8-43cf-8b86-1861fc3a2622"
   },
   "source": [
    "#### Before proceeding, for reproducibility, we fix the random seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91f6229e-94a2-4bb2-bc62-5a9cb6a727c1",
   "metadata": {
    "id": "91f6229e-94a2-4bb2-bc62-5a9cb6a727c1"
   },
   "outputs": [],
   "source": [
    "def set_reproducibility(seed: int) -> None:\n",
    "    \"\"\"\n",
    "    Fixes a given seed for the pseudo-random number generators.\n",
    "    Args:\n",
    "        seed (int): seed to fix\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f7e39c0-587c-432c-8884-7c5d61289b77",
   "metadata": {
    "id": "7f7e39c0-587c-432c-8884-7c5d61289b77"
   },
   "outputs": [],
   "source": [
    "set_reproducibility(stance_config.SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f09a3d-6aa5-4c6f-a085-7cfb63f20bb6",
   "metadata": {
    "id": "73f09a3d-6aa5-4c6f-a085-7cfb63f20bb6"
   },
   "source": [
    "#### Defining the train, val, test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f71d4cef-69ac-4e9a-85df-f3d0540b3b0e",
   "metadata": {
    "id": "f71d4cef-69ac-4e9a-85df-f3d0540b3b0e"
   },
   "outputs": [],
   "source": [
    "def train_val_test_splits(df: pd.DataFrame, ratios:dict) -> dict:\n",
    "    \"\"\"\n",
    "    Splits a given DataFrame into train, val and test, according to the provided ratios.\n",
    "    The dataframe is expected to contain the columns \"question\" and \"answer\". Other columns will be ignored.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame that has to be splitted into train, val and test sets.\n",
    "        ratios (dict): The dictionary containing the ratios between the contents of the train, val and test set. Expected keys: 'train', 'val', 'test'. Expected values: positive numbers not exceeding 1.\n",
    "    Returns:\n",
    "        dict: dictionary containing the required splits. Available keys: 'x_train', 'x_val', 'x_test', 'y_train', 'y_val', 'y_test'.\n",
    "    \"\"\"\n",
    "\n",
    "    #Separating \"train\" from \"val and test\"\n",
    "    x_train, x_val_test, y_train, y_val_test = train_test_split(df.loc[:,['question','answer']],df.loc[:,['answer_stance']],test_size=ratios['test'] + ratios['val'], train_size=ratios['train'])\n",
    "    \n",
    "    #Separating \"val\" from \"test\"\n",
    "    x_val, x_test, y_val, y_test = train_test_split(x_val_test,y_val_test,test_size = ratios['test']/(ratios['test'] + ratios['val']), train_size=ratios['val']/(ratios['test'] + ratios['val']))\n",
    "    \n",
    "    return {'x_train': x_train, 'x_val': x_val, 'x_test': x_test, 'y_train': y_train, 'y_val': y_val, 'y_test': y_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f54f921-5254-49eb-a925-322bb93a0a39",
   "metadata": {
    "id": "0f54f921-5254-49eb-a925-322bb93a0a39"
   },
   "outputs": [],
   "source": [
    "ratios = stance_config.TRAIN_VAL_TEST_RATIOS\n",
    "list_ratios = list(ratios.values())\n",
    "\n",
    "#Ensuring that the values represent proper proportions (no zeros allowed).\n",
    "assert np.sum(list_ratios) == 1 and np.sum(np.sign(list_ratios)) == 3, 'Please specfy valid ratios for the \"train, val, test\" split.'\n",
    "\n",
    "ds_splits = {model_nno: None, model_obj: None}\n",
    "ds_splits[model_nno] = train_val_test_splits(df_nno, ratios)\n",
    "ds_splits[model_obj] = train_val_test_splits(df_obj, ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a936fe6-96d4-4b34-8708-7f93a91b8320",
   "metadata": {
    "id": "7a936fe6-96d4-4b34-8708-7f93a91b8320"
   },
   "source": [
    "#### Now processing the sets through the selected `DistilBertTokenizer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "661aa56c-b388-4cdd-b5bb-de05604297f5",
   "metadata": {
    "id": "661aa56c-b388-4cdd-b5bb-de05604297f5"
   },
   "outputs": [],
   "source": [
    "def tokenize_df(question_answer_df: pd.DataFrame, tokenizer: DistilBertTokenizer) -> dict:\n",
    "    \"\"\"\n",
    "    Given a DistilBertTokenizer, the function returns a dictionary containing the tokenized version of the inputs that will be fed to the networks.\n",
    "    \n",
    "    Args:\n",
    "        question_answer_df (pandas.DataFrame): The DataFrame whose contents have to be tokenized.\n",
    "        tokenizer (DistilBertTokenizer): The DistilBertTokenizer instance loaded from a pre-trained model.\n",
    "    Returns:\n",
    "        dict: dictionary containing the tokenized version of the inputs that will be fed to the networks.\n",
    "    \"\"\"\n",
    "    \n",
    "    #From the dataframe we build the list of lists which contains the values of the dataframe. In particular, each\n",
    "    #element of the outer list is a two-elements list containing the values of a certain row of the dataframe.\n",
    "    LL = question_answer_df.values.tolist()\n",
    "    \n",
    "    #Now, the tokenizer can generate the proper arrays that we'll feed to the networks.    \n",
    "    return dict(tokenizer(LL, padding=True, truncation='longest_first', return_tensors='tf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e20acbe8-15b0-44fd-876a-049b6be2f7a0",
   "metadata": {
    "id": "e20acbe8-15b0-44fd-876a-049b6be2f7a0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    }
   ],
   "source": [
    "#Tokenizing the inputs and preparing the outputs\n",
    "for model in [model_nno, model_obj]:\n",
    "    for set_name in ['train','val','test']:\n",
    "        ds_splits[model][f'x_{set_name}'] = tokenize_df(ds_splits[model][f'x_{set_name}'],tokenizer)\n",
    "        ds_splits[model][f'y_{set_name}'] = ds_splits[model][f'y_{set_name}'].to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415e181f-1144-4c2c-9293-0a9df8c7822a",
   "metadata": {
    "id": "415e181f-1144-4c2c-9293-0a9df8c7822a"
   },
   "source": [
    "#### Now configuring the callbacks for the training of the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c2d27c0-6505-4d4c-9088-4422728dd6fc",
   "metadata": {
    "id": "9c2d27c0-6505-4d4c-9088-4422728dd6fc"
   },
   "outputs": [],
   "source": [
    "model_nno_checkpoint = keras.callbacks.ModelCheckpoint(stance_config.MODEL_NNO_CHECKPOINT_FOLDER, save_best_only=True, save_weights_only=True, verbose=1, mode=\"min\", monitor=\"val_loss\")\n",
    "model_obj_checkpoint = keras.callbacks.ModelCheckpoint(stance_config.MODEL_OBJ_CHECKPOINT_FOLDER, save_best_only=True, save_weights_only=True, verbose=1, mode=\"min\", monitor=\"val_loss\")\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', factor=.1, patience=5, min_lr=stance_config.MIN_LR)\n",
    "\n",
    "model_callbacks = {model_nno: [model_nno_checkpoint, reduce_lr], model_obj: [model_obj_checkpoint, reduce_lr]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cc39e2-20f7-4e99-b02b-5d2e65b9a95d",
   "metadata": {
    "id": "d6cc39e2-20f7-4e99-b02b-5d2e65b9a95d"
   },
   "source": [
    "#### Ensuring that the folders needed to store the best weights of the networks exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01b35863-029a-4e59-8393-225561b904cb",
   "metadata": {
    "id": "01b35863-029a-4e59-8393-225561b904cb"
   },
   "outputs": [],
   "source": [
    "os.makedirs(stance_config.MODEL_NNO_CHECKPOINT_FOLDER, exist_ok = True)\n",
    "os.makedirs(stance_config.MODEL_OBJ_CHECKPOINT_FOLDER, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32e0ed7-13d1-4c0d-85c3-e4dcbf9f105e",
   "metadata": {
    "id": "d32e0ed7-13d1-4c0d-85c3-e4dcbf9f105e"
   },
   "source": [
    "#### Starting the training of the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fdfcffb9-9952-4924-a6ca-8ed03ad2dd31",
   "metadata": {
    "id": "fdfcffb9-9952-4924-a6ca-8ed03ad2dd31"
   },
   "outputs": [],
   "source": [
    "histories = {model_nno: None, model_obj: None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d4ed6fb-0a89-4c18-9ba1-f06206efa109",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6d4ed6fb-0a89-4c18-9ba1-f06206efa109",
    "outputId": "2e9adfd4-362f-4a36-8f68-eefe484744c8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 3.1413 - sparse_categorical_accuracy: 0.3325\n",
      "Epoch 1: val_loss improved from inf to 3.59115, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 25s 381ms/step - loss: 3.1413 - sparse_categorical_accuracy: 0.3325 - val_loss: 3.5912 - val_sparse_categorical_accuracy: 0.2812 - lr: 1.0000e-05\n",
      "Epoch 2/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 2.6535 - sparse_categorical_accuracy: 0.3573\n",
      "Epoch 2: val_loss improved from 3.59115 to 3.13424, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 18s 370ms/step - loss: 2.6535 - sparse_categorical_accuracy: 0.3573 - val_loss: 3.1342 - val_sparse_categorical_accuracy: 0.2812 - lr: 1.0000e-05\n",
      "Epoch 3/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 2.4056 - sparse_categorical_accuracy: 0.3455\n",
      "Epoch 3: val_loss improved from 3.13424 to 2.69428, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 2.4056 - sparse_categorical_accuracy: 0.3455 - val_loss: 2.6943 - val_sparse_categorical_accuracy: 0.2812 - lr: 1.0000e-05\n",
      "Epoch 4/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 2.0704 - sparse_categorical_accuracy: 0.3325\n",
      "Epoch 4: val_loss improved from 2.69428 to 2.29387, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 18s 367ms/step - loss: 2.0704 - sparse_categorical_accuracy: 0.3325 - val_loss: 2.2939 - val_sparse_categorical_accuracy: 0.3021 - lr: 1.0000e-05\n",
      "Epoch 5/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.7741 - sparse_categorical_accuracy: 0.3560\n",
      "Epoch 5: val_loss improved from 2.29387 to 1.94395, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 18s 368ms/step - loss: 1.7741 - sparse_categorical_accuracy: 0.3560 - val_loss: 1.9439 - val_sparse_categorical_accuracy: 0.3021 - lr: 1.0000e-05\n",
      "Epoch 6/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.5370 - sparse_categorical_accuracy: 0.3783\n",
      "Epoch 6: val_loss improved from 1.94395 to 1.65698, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 18s 367ms/step - loss: 1.5370 - sparse_categorical_accuracy: 0.3783 - val_loss: 1.6570 - val_sparse_categorical_accuracy: 0.3125 - lr: 1.0000e-05\n",
      "Epoch 7/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.3780 - sparse_categorical_accuracy: 0.3770\n",
      "Epoch 7: val_loss improved from 1.65698 to 1.42656, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 18s 366ms/step - loss: 1.3780 - sparse_categorical_accuracy: 0.3770 - val_loss: 1.4266 - val_sparse_categorical_accuracy: 0.3750 - lr: 1.0000e-05\n",
      "Epoch 8/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.2086 - sparse_categorical_accuracy: 0.4293\n",
      "Epoch 8: val_loss improved from 1.42656 to 1.25954, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 18s 368ms/step - loss: 1.2086 - sparse_categorical_accuracy: 0.4293 - val_loss: 1.2595 - val_sparse_categorical_accuracy: 0.4167 - lr: 1.0000e-05\n",
      "Epoch 9/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.1225 - sparse_categorical_accuracy: 0.4660\n",
      "Epoch 9: val_loss improved from 1.25954 to 1.14395, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 1.1225 - sparse_categorical_accuracy: 0.4660 - val_loss: 1.1440 - val_sparse_categorical_accuracy: 0.4688 - lr: 1.0000e-05\n",
      "Epoch 10/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.0454 - sparse_categorical_accuracy: 0.5105\n",
      "Epoch 10: val_loss improved from 1.14395 to 1.06388, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 1.0454 - sparse_categorical_accuracy: 0.5105 - val_loss: 1.0639 - val_sparse_categorical_accuracy: 0.5521 - lr: 1.0000e-05\n",
      "Epoch 11/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.0058 - sparse_categorical_accuracy: 0.5550\n",
      "Epoch 11: val_loss improved from 1.06388 to 1.00743, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 1.0058 - sparse_categorical_accuracy: 0.5550 - val_loss: 1.0074 - val_sparse_categorical_accuracy: 0.5938 - lr: 1.0000e-05\n",
      "Epoch 12/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.9643 - sparse_categorical_accuracy: 0.5654\n",
      "Epoch 12: val_loss improved from 1.00743 to 0.96486, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.9643 - sparse_categorical_accuracy: 0.5654 - val_loss: 0.9649 - val_sparse_categorical_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 13/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.9315 - sparse_categorical_accuracy: 0.5942\n",
      "Epoch 13: val_loss improved from 0.96486 to 0.93198, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.9315 - sparse_categorical_accuracy: 0.5942 - val_loss: 0.9320 - val_sparse_categorical_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 14/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.9036 - sparse_categorical_accuracy: 0.6047\n",
      "Epoch 14: val_loss improved from 0.93198 to 0.90868, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.9036 - sparse_categorical_accuracy: 0.6047 - val_loss: 0.9087 - val_sparse_categorical_accuracy: 0.6042 - lr: 1.0000e-05\n",
      "Epoch 15/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8963 - sparse_categorical_accuracy: 0.5995\n",
      "Epoch 15: val_loss improved from 0.90868 to 0.89009, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.8963 - sparse_categorical_accuracy: 0.5995 - val_loss: 0.8901 - val_sparse_categorical_accuracy: 0.6042 - lr: 1.0000e-05\n",
      "Epoch 16/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8805 - sparse_categorical_accuracy: 0.6021\n",
      "Epoch 16: val_loss improved from 0.89009 to 0.87504, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.8805 - sparse_categorical_accuracy: 0.6021 - val_loss: 0.8750 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-05\n",
      "Epoch 17/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8740 - sparse_categorical_accuracy: 0.5982\n",
      "Epoch 17: val_loss improved from 0.87504 to 0.86186, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 18s 366ms/step - loss: 0.8740 - sparse_categorical_accuracy: 0.5982 - val_loss: 0.8619 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 18/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8588 - sparse_categorical_accuracy: 0.6086\n",
      "Epoch 18: val_loss improved from 0.86186 to 0.85084, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.8588 - sparse_categorical_accuracy: 0.6086 - val_loss: 0.8508 - val_sparse_categorical_accuracy: 0.6771 - lr: 1.0000e-05\n",
      "Epoch 19/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8560 - sparse_categorical_accuracy: 0.6139\n",
      "Epoch 19: val_loss improved from 0.85084 to 0.84382, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.8560 - sparse_categorical_accuracy: 0.6139 - val_loss: 0.8438 - val_sparse_categorical_accuracy: 0.6771 - lr: 1.0000e-05\n",
      "Epoch 20/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8471 - sparse_categorical_accuracy: 0.6086\n",
      "Epoch 20: val_loss improved from 0.84382 to 0.83793, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.8471 - sparse_categorical_accuracy: 0.6086 - val_loss: 0.8379 - val_sparse_categorical_accuracy: 0.6771 - lr: 1.0000e-05\n",
      "Epoch 21/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8468 - sparse_categorical_accuracy: 0.6126\n",
      "Epoch 21: val_loss improved from 0.83793 to 0.83055, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.8468 - sparse_categorical_accuracy: 0.6126 - val_loss: 0.8306 - val_sparse_categorical_accuracy: 0.6771 - lr: 1.0000e-05\n",
      "Epoch 22/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8387 - sparse_categorical_accuracy: 0.6113\n",
      "Epoch 22: val_loss improved from 0.83055 to 0.82621, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.8387 - sparse_categorical_accuracy: 0.6113 - val_loss: 0.8262 - val_sparse_categorical_accuracy: 0.6667 - lr: 1.0000e-05\n",
      "Epoch 23/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8369 - sparse_categorical_accuracy: 0.6086\n",
      "Epoch 23: val_loss improved from 0.82621 to 0.82166, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.8369 - sparse_categorical_accuracy: 0.6086 - val_loss: 0.8217 - val_sparse_categorical_accuracy: 0.6667 - lr: 1.0000e-05\n",
      "Epoch 24/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8405 - sparse_categorical_accuracy: 0.6243\n",
      "Epoch 24: val_loss improved from 0.82166 to 0.81644, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.8405 - sparse_categorical_accuracy: 0.6243 - val_loss: 0.8164 - val_sparse_categorical_accuracy: 0.6667 - lr: 1.0000e-05\n",
      "Epoch 25/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8244 - sparse_categorical_accuracy: 0.6204\n",
      "Epoch 25: val_loss improved from 0.81644 to 0.81371, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.8244 - sparse_categorical_accuracy: 0.6204 - val_loss: 0.8137 - val_sparse_categorical_accuracy: 0.6771 - lr: 1.0000e-05\n",
      "Epoch 26/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8305 - sparse_categorical_accuracy: 0.6113\n",
      "Epoch 26: val_loss improved from 0.81371 to 0.81090, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.8305 - sparse_categorical_accuracy: 0.6113 - val_loss: 0.8109 - val_sparse_categorical_accuracy: 0.6771 - lr: 1.0000e-05\n",
      "Epoch 27/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8275 - sparse_categorical_accuracy: 0.6126\n",
      "Epoch 27: val_loss improved from 0.81090 to 0.80710, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.8275 - sparse_categorical_accuracy: 0.6126 - val_loss: 0.8071 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 28/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8174 - sparse_categorical_accuracy: 0.6270\n",
      "Epoch 28: val_loss improved from 0.80710 to 0.80431, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.8174 - sparse_categorical_accuracy: 0.6270 - val_loss: 0.8043 - val_sparse_categorical_accuracy: 0.6667 - lr: 1.0000e-05\n",
      "Epoch 29/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8248 - sparse_categorical_accuracy: 0.6139\n",
      "Epoch 29: val_loss improved from 0.80431 to 0.80219, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.8248 - sparse_categorical_accuracy: 0.6139 - val_loss: 0.8022 - val_sparse_categorical_accuracy: 0.6667 - lr: 1.0000e-05\n",
      "Epoch 30/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8169 - sparse_categorical_accuracy: 0.6191\n",
      "Epoch 30: val_loss improved from 0.80219 to 0.80001, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.8169 - sparse_categorical_accuracy: 0.6191 - val_loss: 0.8000 - val_sparse_categorical_accuracy: 0.6667 - lr: 1.0000e-05\n",
      "Epoch 31/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8191 - sparse_categorical_accuracy: 0.6099\n",
      "Epoch 31: val_loss improved from 0.80001 to 0.79916, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.8191 - sparse_categorical_accuracy: 0.6099 - val_loss: 0.7992 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 32/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8130 - sparse_categorical_accuracy: 0.6270\n",
      "Epoch 32: val_loss improved from 0.79916 to 0.79677, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.8130 - sparse_categorical_accuracy: 0.6270 - val_loss: 0.7968 - val_sparse_categorical_accuracy: 0.6667 - lr: 1.0000e-05\n",
      "Epoch 33/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8131 - sparse_categorical_accuracy: 0.6270\n",
      "Epoch 33: val_loss improved from 0.79677 to 0.79464, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.8131 - sparse_categorical_accuracy: 0.6270 - val_loss: 0.7946 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 34/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8072 - sparse_categorical_accuracy: 0.6387\n",
      "Epoch 34: val_loss improved from 0.79464 to 0.79342, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.8072 - sparse_categorical_accuracy: 0.6387 - val_loss: 0.7934 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 35/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8071 - sparse_categorical_accuracy: 0.6230\n",
      "Epoch 35: val_loss improved from 0.79342 to 0.79112, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.8071 - sparse_categorical_accuracy: 0.6230 - val_loss: 0.7911 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 36/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8066 - sparse_categorical_accuracy: 0.6257\n",
      "Epoch 36: val_loss improved from 0.79112 to 0.78957, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.8066 - sparse_categorical_accuracy: 0.6257 - val_loss: 0.7896 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 37/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8023 - sparse_categorical_accuracy: 0.6283\n",
      "Epoch 37: val_loss improved from 0.78957 to 0.78837, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.8023 - sparse_categorical_accuracy: 0.6283 - val_loss: 0.7884 - val_sparse_categorical_accuracy: 0.6667 - lr: 1.0000e-05\n",
      "Epoch 38/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8047 - sparse_categorical_accuracy: 0.6322\n",
      "Epoch 38: val_loss improved from 0.78837 to 0.78767, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.8047 - sparse_categorical_accuracy: 0.6322 - val_loss: 0.7877 - val_sparse_categorical_accuracy: 0.6667 - lr: 1.0000e-05\n",
      "Epoch 39/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8009 - sparse_categorical_accuracy: 0.6374\n",
      "Epoch 39: val_loss improved from 0.78767 to 0.78586, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.8009 - sparse_categorical_accuracy: 0.6374 - val_loss: 0.7859 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 40/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.8067 - sparse_categorical_accuracy: 0.6243\n",
      "Epoch 40: val_loss improved from 0.78586 to 0.78375, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.8067 - sparse_categorical_accuracy: 0.6243 - val_loss: 0.7838 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 41/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7940 - sparse_categorical_accuracy: 0.6348\n",
      "Epoch 41: val_loss improved from 0.78375 to 0.78310, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7940 - sparse_categorical_accuracy: 0.6348 - val_loss: 0.7831 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 42/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7946 - sparse_categorical_accuracy: 0.6387\n",
      "Epoch 42: val_loss improved from 0.78310 to 0.78139, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7946 - sparse_categorical_accuracy: 0.6387 - val_loss: 0.7814 - val_sparse_categorical_accuracy: 0.6667 - lr: 1.0000e-05\n",
      "Epoch 43/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7986 - sparse_categorical_accuracy: 0.6374\n",
      "Epoch 43: val_loss improved from 0.78139 to 0.78026, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7986 - sparse_categorical_accuracy: 0.6374 - val_loss: 0.7803 - val_sparse_categorical_accuracy: 0.6667 - lr: 1.0000e-05\n",
      "Epoch 44/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7956 - sparse_categorical_accuracy: 0.6296\n",
      "Epoch 44: val_loss improved from 0.78026 to 0.77943, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7956 - sparse_categorical_accuracy: 0.6296 - val_loss: 0.7794 - val_sparse_categorical_accuracy: 0.6667 - lr: 1.0000e-05\n",
      "Epoch 45/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7972 - sparse_categorical_accuracy: 0.6361\n",
      "Epoch 45: val_loss improved from 0.77943 to 0.77807, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7972 - sparse_categorical_accuracy: 0.6361 - val_loss: 0.7781 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 46/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7859 - sparse_categorical_accuracy: 0.6361\n",
      "Epoch 46: val_loss improved from 0.77807 to 0.77674, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7859 - sparse_categorical_accuracy: 0.6361 - val_loss: 0.7767 - val_sparse_categorical_accuracy: 0.6667 - lr: 1.0000e-05\n",
      "Epoch 47/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7919 - sparse_categorical_accuracy: 0.6335\n",
      "Epoch 47: val_loss improved from 0.77674 to 0.77599, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7919 - sparse_categorical_accuracy: 0.6335 - val_loss: 0.7760 - val_sparse_categorical_accuracy: 0.6667 - lr: 1.0000e-05\n",
      "Epoch 48/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7891 - sparse_categorical_accuracy: 0.6440\n",
      "Epoch 48: val_loss improved from 0.77599 to 0.77539, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7891 - sparse_categorical_accuracy: 0.6440 - val_loss: 0.7754 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 49/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7817 - sparse_categorical_accuracy: 0.6479\n",
      "Epoch 49: val_loss improved from 0.77539 to 0.77532, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7817 - sparse_categorical_accuracy: 0.6479 - val_loss: 0.7753 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 50/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7831 - sparse_categorical_accuracy: 0.6387\n",
      "Epoch 50: val_loss improved from 0.77532 to 0.77391, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7831 - sparse_categorical_accuracy: 0.6387 - val_loss: 0.7739 - val_sparse_categorical_accuracy: 0.6667 - lr: 1.0000e-05\n",
      "Epoch 51/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7786 - sparse_categorical_accuracy: 0.6427\n",
      "Epoch 51: val_loss improved from 0.77391 to 0.77327, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7786 - sparse_categorical_accuracy: 0.6427 - val_loss: 0.7733 - val_sparse_categorical_accuracy: 0.6667 - lr: 1.0000e-05\n",
      "Epoch 52/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7771 - sparse_categorical_accuracy: 0.6401\n",
      "Epoch 52: val_loss did not improve from 0.77327\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.7771 - sparse_categorical_accuracy: 0.6401 - val_loss: 0.7737 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 53/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7774 - sparse_categorical_accuracy: 0.6571\n",
      "Epoch 53: val_loss improved from 0.77327 to 0.77172, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7774 - sparse_categorical_accuracy: 0.6571 - val_loss: 0.7717 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 54/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7698 - sparse_categorical_accuracy: 0.6623\n",
      "Epoch 54: val_loss improved from 0.77172 to 0.77058, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7698 - sparse_categorical_accuracy: 0.6623 - val_loss: 0.7706 - val_sparse_categorical_accuracy: 0.6667 - lr: 1.0000e-05\n",
      "Epoch 55/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7697 - sparse_categorical_accuracy: 0.6479\n",
      "Epoch 55: val_loss improved from 0.77058 to 0.76993, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7697 - sparse_categorical_accuracy: 0.6479 - val_loss: 0.7699 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-05\n",
      "Epoch 56/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7754 - sparse_categorical_accuracy: 0.6479\n",
      "Epoch 56: val_loss improved from 0.76993 to 0.76911, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7754 - sparse_categorical_accuracy: 0.6479 - val_loss: 0.7691 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 57/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7704 - sparse_categorical_accuracy: 0.6636\n",
      "Epoch 57: val_loss improved from 0.76911 to 0.76909, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7704 - sparse_categorical_accuracy: 0.6636 - val_loss: 0.7691 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 58/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7688 - sparse_categorical_accuracy: 0.6531\n",
      "Epoch 58: val_loss improved from 0.76909 to 0.76871, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7688 - sparse_categorical_accuracy: 0.6531 - val_loss: 0.7687 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 59/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7622 - sparse_categorical_accuracy: 0.6531\n",
      "Epoch 59: val_loss did not improve from 0.76871\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.7622 - sparse_categorical_accuracy: 0.6531 - val_loss: 0.7687 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 60/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7638 - sparse_categorical_accuracy: 0.6597\n",
      "Epoch 60: val_loss improved from 0.76871 to 0.76745, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7638 - sparse_categorical_accuracy: 0.6597 - val_loss: 0.7675 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 61/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7641 - sparse_categorical_accuracy: 0.6584\n",
      "Epoch 61: val_loss did not improve from 0.76745\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.7641 - sparse_categorical_accuracy: 0.6584 - val_loss: 0.7679 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 62/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7652 - sparse_categorical_accuracy: 0.6597\n",
      "Epoch 62: val_loss did not improve from 0.76745\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.7652 - sparse_categorical_accuracy: 0.6597 - val_loss: 0.7677 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 63/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7596 - sparse_categorical_accuracy: 0.6545\n",
      "Epoch 63: val_loss improved from 0.76745 to 0.76677, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 18s 366ms/step - loss: 0.7596 - sparse_categorical_accuracy: 0.6545 - val_loss: 0.7668 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 64/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7567 - sparse_categorical_accuracy: 0.6584\n",
      "Epoch 64: val_loss improved from 0.76677 to 0.76575, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7567 - sparse_categorical_accuracy: 0.6584 - val_loss: 0.7658 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 65/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7574 - sparse_categorical_accuracy: 0.6793\n",
      "Epoch 65: val_loss improved from 0.76575 to 0.76489, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7574 - sparse_categorical_accuracy: 0.6793 - val_loss: 0.7649 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 66/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7562 - sparse_categorical_accuracy: 0.6597\n",
      "Epoch 66: val_loss improved from 0.76489 to 0.76356, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7562 - sparse_categorical_accuracy: 0.6597 - val_loss: 0.7636 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 67/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7477 - sparse_categorical_accuracy: 0.6728\n",
      "Epoch 67: val_loss improved from 0.76356 to 0.76293, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7477 - sparse_categorical_accuracy: 0.6728 - val_loss: 0.7629 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-05\n",
      "Epoch 68/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7532 - sparse_categorical_accuracy: 0.6610\n",
      "Epoch 68: val_loss did not improve from 0.76293\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.7532 - sparse_categorical_accuracy: 0.6610 - val_loss: 0.7633 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-05\n",
      "Epoch 69/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7448 - sparse_categorical_accuracy: 0.6649\n",
      "Epoch 69: val_loss improved from 0.76293 to 0.76211, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7448 - sparse_categorical_accuracy: 0.6649 - val_loss: 0.7621 - val_sparse_categorical_accuracy: 0.6354 - lr: 1.0000e-05\n",
      "Epoch 70/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7442 - sparse_categorical_accuracy: 0.6610\n",
      "Epoch 70: val_loss improved from 0.76211 to 0.76188, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7442 - sparse_categorical_accuracy: 0.6610 - val_loss: 0.7619 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-05\n",
      "Epoch 71/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7524 - sparse_categorical_accuracy: 0.6571\n",
      "Epoch 71: val_loss did not improve from 0.76188\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.7524 - sparse_categorical_accuracy: 0.6571 - val_loss: 0.7620 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-05\n",
      "Epoch 72/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7351 - sparse_categorical_accuracy: 0.6702\n",
      "Epoch 72: val_loss did not improve from 0.76188\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.7351 - sparse_categorical_accuracy: 0.6702 - val_loss: 0.7622 - val_sparse_categorical_accuracy: 0.6354 - lr: 1.0000e-05\n",
      "Epoch 73/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7433 - sparse_categorical_accuracy: 0.6610\n",
      "Epoch 73: val_loss did not improve from 0.76188\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.7433 - sparse_categorical_accuracy: 0.6610 - val_loss: 0.7619 - val_sparse_categorical_accuracy: 0.6354 - lr: 1.0000e-05\n",
      "Epoch 74/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7395 - sparse_categorical_accuracy: 0.6715\n",
      "Epoch 74: val_loss improved from 0.76188 to 0.75989, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7395 - sparse_categorical_accuracy: 0.6715 - val_loss: 0.7599 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-05\n",
      "Epoch 75/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7345 - sparse_categorical_accuracy: 0.6610\n",
      "Epoch 75: val_loss improved from 0.75989 to 0.75841, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 18s 366ms/step - loss: 0.7345 - sparse_categorical_accuracy: 0.6610 - val_loss: 0.7584 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-05\n",
      "Epoch 76/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7375 - sparse_categorical_accuracy: 0.6793\n",
      "Epoch 76: val_loss did not improve from 0.75841\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.7375 - sparse_categorical_accuracy: 0.6793 - val_loss: 0.7594 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-05\n",
      "Epoch 77/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7303 - sparse_categorical_accuracy: 0.6846\n",
      "Epoch 77: val_loss did not improve from 0.75841\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.7303 - sparse_categorical_accuracy: 0.6846 - val_loss: 0.7598 - val_sparse_categorical_accuracy: 0.6354 - lr: 1.0000e-05\n",
      "Epoch 78/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7342 - sparse_categorical_accuracy: 0.6662\n",
      "Epoch 78: val_loss did not improve from 0.75841\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.7342 - sparse_categorical_accuracy: 0.6662 - val_loss: 0.7594 - val_sparse_categorical_accuracy: 0.6354 - lr: 1.0000e-05\n",
      "Epoch 79/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7294 - sparse_categorical_accuracy: 0.6754\n",
      "Epoch 79: val_loss improved from 0.75841 to 0.75754, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 18s 366ms/step - loss: 0.7294 - sparse_categorical_accuracy: 0.6754 - val_loss: 0.7575 - val_sparse_categorical_accuracy: 0.6250 - lr: 1.0000e-05\n",
      "Epoch 80/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7246 - sparse_categorical_accuracy: 0.6832\n",
      "Epoch 80: val_loss did not improve from 0.75754\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.7246 - sparse_categorical_accuracy: 0.6832 - val_loss: 0.7582 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-05\n",
      "Epoch 81/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7329 - sparse_categorical_accuracy: 0.6715\n",
      "Epoch 81: val_loss did not improve from 0.75754\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.7329 - sparse_categorical_accuracy: 0.6715 - val_loss: 0.7585 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-05\n",
      "Epoch 82/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7365 - sparse_categorical_accuracy: 0.6675\n",
      "Epoch 82: val_loss did not improve from 0.75754\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.7365 - sparse_categorical_accuracy: 0.6675 - val_loss: 0.7579 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-05\n",
      "Epoch 83/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7270 - sparse_categorical_accuracy: 0.6859\n",
      "Epoch 83: val_loss did not improve from 0.75754\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.7270 - sparse_categorical_accuracy: 0.6859 - val_loss: 0.7577 - val_sparse_categorical_accuracy: 0.6354 - lr: 1.0000e-05\n",
      "Epoch 84/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7228 - sparse_categorical_accuracy: 0.6793\n",
      "Epoch 84: val_loss improved from 0.75754 to 0.75602, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 18s 366ms/step - loss: 0.7228 - sparse_categorical_accuracy: 0.6793 - val_loss: 0.7560 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-05\n",
      "Epoch 85/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7199 - sparse_categorical_accuracy: 0.6754\n",
      "Epoch 85: val_loss improved from 0.75602 to 0.75572, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7199 - sparse_categorical_accuracy: 0.6754 - val_loss: 0.7557 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 86/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7206 - sparse_categorical_accuracy: 0.6793\n",
      "Epoch 86: val_loss improved from 0.75572 to 0.75464, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 18s 366ms/step - loss: 0.7206 - sparse_categorical_accuracy: 0.6793 - val_loss: 0.7546 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 87/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7097 - sparse_categorical_accuracy: 0.6950\n",
      "Epoch 87: val_loss did not improve from 0.75464\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.7097 - sparse_categorical_accuracy: 0.6950 - val_loss: 0.7547 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 88/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7207 - sparse_categorical_accuracy: 0.6950\n",
      "Epoch 88: val_loss improved from 0.75464 to 0.75344, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7207 - sparse_categorical_accuracy: 0.6950 - val_loss: 0.7534 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 89/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7160 - sparse_categorical_accuracy: 0.6898\n",
      "Epoch 89: val_loss improved from 0.75344 to 0.75180, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 18s 366ms/step - loss: 0.7160 - sparse_categorical_accuracy: 0.6898 - val_loss: 0.7518 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 90/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7165 - sparse_categorical_accuracy: 0.6793\n",
      "Epoch 90: val_loss improved from 0.75180 to 0.75164, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7165 - sparse_categorical_accuracy: 0.6793 - val_loss: 0.7516 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 91/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7159 - sparse_categorical_accuracy: 0.6728\n",
      "Epoch 91: val_loss did not improve from 0.75164\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.7159 - sparse_categorical_accuracy: 0.6728 - val_loss: 0.7523 - val_sparse_categorical_accuracy: 0.6667 - lr: 1.0000e-05\n",
      "Epoch 92/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7145 - sparse_categorical_accuracy: 0.6872\n",
      "Epoch 92: val_loss improved from 0.75164 to 0.75102, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7145 - sparse_categorical_accuracy: 0.6872 - val_loss: 0.7510 - val_sparse_categorical_accuracy: 0.6667 - lr: 1.0000e-05\n",
      "Epoch 93/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7108 - sparse_categorical_accuracy: 0.6963\n",
      "Epoch 93: val_loss improved from 0.75102 to 0.75091, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7108 - sparse_categorical_accuracy: 0.6963 - val_loss: 0.7509 - val_sparse_categorical_accuracy: 0.6667 - lr: 1.0000e-05\n",
      "Epoch 94/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7034 - sparse_categorical_accuracy: 0.6885\n",
      "Epoch 94: val_loss improved from 0.75091 to 0.75070, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7034 - sparse_categorical_accuracy: 0.6885 - val_loss: 0.7507 - val_sparse_categorical_accuracy: 0.6667 - lr: 1.0000e-05\n",
      "Epoch 95/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7073 - sparse_categorical_accuracy: 0.6846\n",
      "Epoch 95: val_loss improved from 0.75070 to 0.74891, saving model to ./model_nno_checkpoint\\\n",
      "48/48 [==============================] - 17s 365ms/step - loss: 0.7073 - sparse_categorical_accuracy: 0.6846 - val_loss: 0.7489 - val_sparse_categorical_accuracy: 0.6667 - lr: 1.0000e-05\n",
      "Epoch 96/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7064 - sparse_categorical_accuracy: 0.6963\n",
      "Epoch 96: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.7064 - sparse_categorical_accuracy: 0.6963 - val_loss: 0.7499 - val_sparse_categorical_accuracy: 0.6667 - lr: 1.0000e-05\n",
      "Epoch 97/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7038 - sparse_categorical_accuracy: 0.6924\n",
      "Epoch 97: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.7038 - sparse_categorical_accuracy: 0.6924 - val_loss: 0.7489 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 98/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7044 - sparse_categorical_accuracy: 0.6911\n",
      "Epoch 98: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.7044 - sparse_categorical_accuracy: 0.6911 - val_loss: 0.7508 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 99/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6996 - sparse_categorical_accuracy: 0.6872\n",
      "Epoch 99: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.6996 - sparse_categorical_accuracy: 0.6872 - val_loss: 0.7501 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 100/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6981 - sparse_categorical_accuracy: 0.6819\n",
      "Epoch 100: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.6981 - sparse_categorical_accuracy: 0.6819 - val_loss: 0.7498 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-05\n",
      "Epoch 101/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6904 - sparse_categorical_accuracy: 0.6976\n",
      "Epoch 101: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.6904 - sparse_categorical_accuracy: 0.6976 - val_loss: 0.7497 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-06\n",
      "Epoch 102/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6990 - sparse_categorical_accuracy: 0.6872\n",
      "Epoch 102: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.6990 - sparse_categorical_accuracy: 0.6872 - val_loss: 0.7498 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-06\n",
      "Epoch 103/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7049 - sparse_categorical_accuracy: 0.6950\n",
      "Epoch 103: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.7049 - sparse_categorical_accuracy: 0.6950 - val_loss: 0.7497 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-06\n",
      "Epoch 104/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6904 - sparse_categorical_accuracy: 0.6990\n",
      "Epoch 104: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.6904 - sparse_categorical_accuracy: 0.6990 - val_loss: 0.7497 - val_sparse_categorical_accuracy: 0.6562 - lr: 1.0000e-06\n",
      "Epoch 105/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6998 - sparse_categorical_accuracy: 0.6976\n",
      "Epoch 105: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.6998 - sparse_categorical_accuracy: 0.6976 - val_loss: 0.7495 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-06\n",
      "Epoch 106/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7034 - sparse_categorical_accuracy: 0.7055\n",
      "Epoch 106: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.7034 - sparse_categorical_accuracy: 0.7055 - val_loss: 0.7495 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-07\n",
      "Epoch 107/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6989 - sparse_categorical_accuracy: 0.6924\n",
      "Epoch 107: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.6989 - sparse_categorical_accuracy: 0.6924 - val_loss: 0.7495 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-07\n",
      "Epoch 108/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6983 - sparse_categorical_accuracy: 0.7003\n",
      "Epoch 108: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.6983 - sparse_categorical_accuracy: 0.7003 - val_loss: 0.7495 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-07\n",
      "Epoch 109/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7038 - sparse_categorical_accuracy: 0.6859\n",
      "Epoch 109: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.7038 - sparse_categorical_accuracy: 0.6859 - val_loss: 0.7495 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-07\n",
      "Epoch 110/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7008 - sparse_categorical_accuracy: 0.6898\n",
      "Epoch 110: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.7008 - sparse_categorical_accuracy: 0.6898 - val_loss: 0.7495 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-07\n",
      "Epoch 111/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7046 - sparse_categorical_accuracy: 0.6990\n",
      "Epoch 111: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.7046 - sparse_categorical_accuracy: 0.6990 - val_loss: 0.7495 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 112/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6974 - sparse_categorical_accuracy: 0.6976\n",
      "Epoch 112: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.6974 - sparse_categorical_accuracy: 0.6976 - val_loss: 0.7495 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 113/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7047 - sparse_categorical_accuracy: 0.7029\n",
      "Epoch 113: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.7047 - sparse_categorical_accuracy: 0.7029 - val_loss: 0.7495 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 114/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6928 - sparse_categorical_accuracy: 0.6898\n",
      "Epoch 114: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.6928 - sparse_categorical_accuracy: 0.6898 - val_loss: 0.7495 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 115/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6962 - sparse_categorical_accuracy: 0.6806\n",
      "Epoch 115: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.6962 - sparse_categorical_accuracy: 0.6806 - val_loss: 0.7495 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 116/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6911 - sparse_categorical_accuracy: 0.7081\n",
      "Epoch 116: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.6911 - sparse_categorical_accuracy: 0.7081 - val_loss: 0.7495 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 117/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6883 - sparse_categorical_accuracy: 0.7003\n",
      "Epoch 117: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.6883 - sparse_categorical_accuracy: 0.7003 - val_loss: 0.7495 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 118/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7055 - sparse_categorical_accuracy: 0.6898\n",
      "Epoch 118: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.7055 - sparse_categorical_accuracy: 0.6898 - val_loss: 0.7495 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 119/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6892 - sparse_categorical_accuracy: 0.6950\n",
      "Epoch 119: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.6892 - sparse_categorical_accuracy: 0.6950 - val_loss: 0.7495 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 120/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6930 - sparse_categorical_accuracy: 0.6950\n",
      "Epoch 120: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.6930 - sparse_categorical_accuracy: 0.6950 - val_loss: 0.7495 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 121/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6952 - sparse_categorical_accuracy: 0.6911\n",
      "Epoch 121: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.6952 - sparse_categorical_accuracy: 0.6911 - val_loss: 0.7495 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 122/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6928 - sparse_categorical_accuracy: 0.6976\n",
      "Epoch 122: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.6928 - sparse_categorical_accuracy: 0.6976 - val_loss: 0.7495 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 123/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7036 - sparse_categorical_accuracy: 0.6911\n",
      "Epoch 123: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.7036 - sparse_categorical_accuracy: 0.6911 - val_loss: 0.7495 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 124/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6938 - sparse_categorical_accuracy: 0.6950\n",
      "Epoch 124: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.6938 - sparse_categorical_accuracy: 0.6950 - val_loss: 0.7495 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 125/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6968 - sparse_categorical_accuracy: 0.6976\n",
      "Epoch 125: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.6968 - sparse_categorical_accuracy: 0.6976 - val_loss: 0.7494 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 126/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6963 - sparse_categorical_accuracy: 0.6950\n",
      "Epoch 126: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.6963 - sparse_categorical_accuracy: 0.6950 - val_loss: 0.7494 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 127/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7028 - sparse_categorical_accuracy: 0.6898\n",
      "Epoch 127: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.7028 - sparse_categorical_accuracy: 0.6898 - val_loss: 0.7494 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 128/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7001 - sparse_categorical_accuracy: 0.6859\n",
      "Epoch 128: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.7001 - sparse_categorical_accuracy: 0.6859 - val_loss: 0.7494 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 129/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6959 - sparse_categorical_accuracy: 0.6976\n",
      "Epoch 129: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.6959 - sparse_categorical_accuracy: 0.6976 - val_loss: 0.7494 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 130/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6949 - sparse_categorical_accuracy: 0.6990\n",
      "Epoch 130: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.6949 - sparse_categorical_accuracy: 0.6990 - val_loss: 0.7494 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 131/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6957 - sparse_categorical_accuracy: 0.6950\n",
      "Epoch 131: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.6957 - sparse_categorical_accuracy: 0.6950 - val_loss: 0.7494 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 132/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6960 - sparse_categorical_accuracy: 0.6911\n",
      "Epoch 132: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.6960 - sparse_categorical_accuracy: 0.6911 - val_loss: 0.7494 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 133/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6936 - sparse_categorical_accuracy: 0.7068\n",
      "Epoch 133: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.6936 - sparse_categorical_accuracy: 0.7068 - val_loss: 0.7494 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 134/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7012 - sparse_categorical_accuracy: 0.7016\n",
      "Epoch 134: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.7012 - sparse_categorical_accuracy: 0.7016 - val_loss: 0.7494 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 135/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6932 - sparse_categorical_accuracy: 0.6924\n",
      "Epoch 135: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.6932 - sparse_categorical_accuracy: 0.6924 - val_loss: 0.7494 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 136/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6969 - sparse_categorical_accuracy: 0.7055\n",
      "Epoch 136: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.6969 - sparse_categorical_accuracy: 0.7055 - val_loss: 0.7494 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 137/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6985 - sparse_categorical_accuracy: 0.6963\n",
      "Epoch 137: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.6985 - sparse_categorical_accuracy: 0.6963 - val_loss: 0.7494 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 138/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6912 - sparse_categorical_accuracy: 0.6976\n",
      "Epoch 138: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.6912 - sparse_categorical_accuracy: 0.6976 - val_loss: 0.7494 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 139/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6921 - sparse_categorical_accuracy: 0.6963\n",
      "Epoch 139: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.6921 - sparse_categorical_accuracy: 0.6963 - val_loss: 0.7494 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 140/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7032 - sparse_categorical_accuracy: 0.6924\n",
      "Epoch 140: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.7032 - sparse_categorical_accuracy: 0.6924 - val_loss: 0.7494 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 141/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6948 - sparse_categorical_accuracy: 0.6990\n",
      "Epoch 141: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.6948 - sparse_categorical_accuracy: 0.6990 - val_loss: 0.7494 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 142/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6993 - sparse_categorical_accuracy: 0.6872\n",
      "Epoch 142: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.6993 - sparse_categorical_accuracy: 0.6872 - val_loss: 0.7494 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 143/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7015 - sparse_categorical_accuracy: 0.7003\n",
      "Epoch 143: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.7015 - sparse_categorical_accuracy: 0.7003 - val_loss: 0.7494 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 144/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6943 - sparse_categorical_accuracy: 0.6872\n",
      "Epoch 144: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.6943 - sparse_categorical_accuracy: 0.6872 - val_loss: 0.7494 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 145/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6890 - sparse_categorical_accuracy: 0.6924\n",
      "Epoch 145: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.6890 - sparse_categorical_accuracy: 0.6924 - val_loss: 0.7494 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 146/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6999 - sparse_categorical_accuracy: 0.6832\n",
      "Epoch 146: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.6999 - sparse_categorical_accuracy: 0.6832 - val_loss: 0.7494 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 147/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6969 - sparse_categorical_accuracy: 0.6885\n",
      "Epoch 147: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 0.6969 - sparse_categorical_accuracy: 0.6885 - val_loss: 0.7494 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 148/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6971 - sparse_categorical_accuracy: 0.7042\n",
      "Epoch 148: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.6971 - sparse_categorical_accuracy: 0.7042 - val_loss: 0.7494 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 149/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7027 - sparse_categorical_accuracy: 0.6819\n",
      "Epoch 149: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.7027 - sparse_categorical_accuracy: 0.6819 - val_loss: 0.7494 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 150/150\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.6932 - sparse_categorical_accuracy: 0.6898\n",
      "Epoch 150: val_loss did not improve from 0.74891\n",
      "48/48 [==============================] - 17s 354ms/step - loss: 0.6932 - sparse_categorical_accuracy: 0.6898 - val_loss: 0.7494 - val_sparse_categorical_accuracy: 0.6458 - lr: 1.0000e-08\n",
      "Epoch 1/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.7181 - sparse_categorical_accuracy: 0.5000\n",
      "Epoch 1: val_loss improved from inf to 0.71249, saving model to ./model_obj_checkpoint\\\n",
      "30/30 [==============================] - 14s 397ms/step - loss: 0.7181 - sparse_categorical_accuracy: 0.5000 - val_loss: 0.7125 - val_sparse_categorical_accuracy: 0.4667 - lr: 1.0000e-05\n",
      "Epoch 2/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.7034 - sparse_categorical_accuracy: 0.4938\n",
      "Epoch 2: val_loss improved from 0.71249 to 0.70833, saving model to ./model_obj_checkpoint\\\n",
      "30/30 [==============================] - 11s 364ms/step - loss: 0.7034 - sparse_categorical_accuracy: 0.4938 - val_loss: 0.7083 - val_sparse_categorical_accuracy: 0.4500 - lr: 1.0000e-05\n",
      "Epoch 3/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6967 - sparse_categorical_accuracy: 0.5083\n",
      "Epoch 3: val_loss improved from 0.70833 to 0.70587, saving model to ./model_obj_checkpoint\\\n",
      "30/30 [==============================] - 11s 364ms/step - loss: 0.6967 - sparse_categorical_accuracy: 0.5083 - val_loss: 0.7059 - val_sparse_categorical_accuracy: 0.4333 - lr: 1.0000e-05\n",
      "Epoch 4/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6936 - sparse_categorical_accuracy: 0.5146\n",
      "Epoch 4: val_loss improved from 0.70587 to 0.70387, saving model to ./model_obj_checkpoint\\\n",
      "30/30 [==============================] - 11s 364ms/step - loss: 0.6936 - sparse_categorical_accuracy: 0.5146 - val_loss: 0.7039 - val_sparse_categorical_accuracy: 0.4333 - lr: 1.0000e-05\n",
      "Epoch 5/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6943 - sparse_categorical_accuracy: 0.5188\n",
      "Epoch 5: val_loss improved from 0.70387 to 0.69978, saving model to ./model_obj_checkpoint\\\n",
      "30/30 [==============================] - 11s 364ms/step - loss: 0.6943 - sparse_categorical_accuracy: 0.5188 - val_loss: 0.6998 - val_sparse_categorical_accuracy: 0.4333 - lr: 1.0000e-05\n",
      "Epoch 6/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6864 - sparse_categorical_accuracy: 0.5667\n",
      "Epoch 6: val_loss improved from 0.69978 to 0.69926, saving model to ./model_obj_checkpoint\\\n",
      "30/30 [==============================] - 11s 364ms/step - loss: 0.6864 - sparse_categorical_accuracy: 0.5667 - val_loss: 0.6993 - val_sparse_categorical_accuracy: 0.4167 - lr: 1.0000e-05\n",
      "Epoch 7/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6828 - sparse_categorical_accuracy: 0.5437\n",
      "Epoch 7: val_loss improved from 0.69926 to 0.69811, saving model to ./model_obj_checkpoint\\\n",
      "30/30 [==============================] - 11s 364ms/step - loss: 0.6828 - sparse_categorical_accuracy: 0.5437 - val_loss: 0.6981 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-05\n",
      "Epoch 8/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6894 - sparse_categorical_accuracy: 0.5250\n",
      "Epoch 8: val_loss improved from 0.69811 to 0.69483, saving model to ./model_obj_checkpoint\\\n",
      "30/30 [==============================] - 11s 364ms/step - loss: 0.6894 - sparse_categorical_accuracy: 0.5250 - val_loss: 0.6948 - val_sparse_categorical_accuracy: 0.5167 - lr: 1.0000e-05\n",
      "Epoch 9/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6863 - sparse_categorical_accuracy: 0.5500\n",
      "Epoch 9: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6863 - sparse_categorical_accuracy: 0.5500 - val_loss: 0.6953 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-05\n",
      "Epoch 10/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6808 - sparse_categorical_accuracy: 0.5750\n",
      "Epoch 10: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6808 - sparse_categorical_accuracy: 0.5750 - val_loss: 0.6955 - val_sparse_categorical_accuracy: 0.5167 - lr: 1.0000e-05\n",
      "Epoch 11/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6822 - sparse_categorical_accuracy: 0.5708\n",
      "Epoch 11: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6822 - sparse_categorical_accuracy: 0.5708 - val_loss: 0.6964 - val_sparse_categorical_accuracy: 0.5167 - lr: 1.0000e-05\n",
      "Epoch 12/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6704 - sparse_categorical_accuracy: 0.5979\n",
      "Epoch 12: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6704 - sparse_categorical_accuracy: 0.5979 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.5000 - lr: 1.0000e-05\n",
      "Epoch 13/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6719 - sparse_categorical_accuracy: 0.5583\n",
      "Epoch 13: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6719 - sparse_categorical_accuracy: 0.5583 - val_loss: 0.6956 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-05\n",
      "Epoch 14/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6717 - sparse_categorical_accuracy: 0.5771\n",
      "Epoch 14: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6717 - sparse_categorical_accuracy: 0.5771 - val_loss: 0.6955 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-06\n",
      "Epoch 15/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6723 - sparse_categorical_accuracy: 0.6021\n",
      "Epoch 15: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6723 - sparse_categorical_accuracy: 0.6021 - val_loss: 0.6955 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-06\n",
      "Epoch 16/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6743 - sparse_categorical_accuracy: 0.5667\n",
      "Epoch 16: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6743 - sparse_categorical_accuracy: 0.5667 - val_loss: 0.6955 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-06\n",
      "Epoch 17/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6735 - sparse_categorical_accuracy: 0.5750\n",
      "Epoch 17: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6735 - sparse_categorical_accuracy: 0.5750 - val_loss: 0.6958 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-06\n",
      "Epoch 18/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6682 - sparse_categorical_accuracy: 0.5750\n",
      "Epoch 18: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6682 - sparse_categorical_accuracy: 0.5750 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-06\n",
      "Epoch 19/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6686 - sparse_categorical_accuracy: 0.5875\n",
      "Epoch 19: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6686 - sparse_categorical_accuracy: 0.5875 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-07\n",
      "Epoch 20/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6665 - sparse_categorical_accuracy: 0.5938\n",
      "Epoch 20: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6665 - sparse_categorical_accuracy: 0.5938 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-07\n",
      "Epoch 21/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6732 - sparse_categorical_accuracy: 0.5896\n",
      "Epoch 21: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6732 - sparse_categorical_accuracy: 0.5896 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-07\n",
      "Epoch 22/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6682 - sparse_categorical_accuracy: 0.6146\n",
      "Epoch 22: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6682 - sparse_categorical_accuracy: 0.6146 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-07\n",
      "Epoch 23/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6685 - sparse_categorical_accuracy: 0.6125\n",
      "Epoch 23: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6685 - sparse_categorical_accuracy: 0.6125 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-07\n",
      "Epoch 24/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6778 - sparse_categorical_accuracy: 0.5667\n",
      "Epoch 24: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6778 - sparse_categorical_accuracy: 0.5667 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 25/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6753 - sparse_categorical_accuracy: 0.5833\n",
      "Epoch 25: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6753 - sparse_categorical_accuracy: 0.5833 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 26/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6798 - sparse_categorical_accuracy: 0.5625\n",
      "Epoch 26: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6798 - sparse_categorical_accuracy: 0.5625 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 27/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6733 - sparse_categorical_accuracy: 0.5833\n",
      "Epoch 27: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6733 - sparse_categorical_accuracy: 0.5833 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 28/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6755 - sparse_categorical_accuracy: 0.5688\n",
      "Epoch 28: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6755 - sparse_categorical_accuracy: 0.5688 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 29/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6779 - sparse_categorical_accuracy: 0.5646\n",
      "Epoch 29: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6779 - sparse_categorical_accuracy: 0.5646 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 30/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6728 - sparse_categorical_accuracy: 0.5688\n",
      "Epoch 30: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6728 - sparse_categorical_accuracy: 0.5688 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 31/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6724 - sparse_categorical_accuracy: 0.5792\n",
      "Epoch 31: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6724 - sparse_categorical_accuracy: 0.5792 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 32/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6713 - sparse_categorical_accuracy: 0.5750\n",
      "Epoch 32: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6713 - sparse_categorical_accuracy: 0.5750 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 33/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6663 - sparse_categorical_accuracy: 0.5917\n",
      "Epoch 33: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6663 - sparse_categorical_accuracy: 0.5917 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 34/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6688 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 34: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6688 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 35/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6698 - sparse_categorical_accuracy: 0.6083\n",
      "Epoch 35: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6698 - sparse_categorical_accuracy: 0.6083 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 36/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6809 - sparse_categorical_accuracy: 0.5729\n",
      "Epoch 36: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6809 - sparse_categorical_accuracy: 0.5729 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 37/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6628 - sparse_categorical_accuracy: 0.6021\n",
      "Epoch 37: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6628 - sparse_categorical_accuracy: 0.6021 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 38/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6707 - sparse_categorical_accuracy: 0.5917\n",
      "Epoch 38: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6707 - sparse_categorical_accuracy: 0.5917 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 39/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6659 - sparse_categorical_accuracy: 0.5792\n",
      "Epoch 39: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6659 - sparse_categorical_accuracy: 0.5792 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 40/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6708 - sparse_categorical_accuracy: 0.5833\n",
      "Epoch 40: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6708 - sparse_categorical_accuracy: 0.5833 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 41/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6726 - sparse_categorical_accuracy: 0.5562\n",
      "Epoch 41: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6726 - sparse_categorical_accuracy: 0.5562 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 42/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6827 - sparse_categorical_accuracy: 0.5667\n",
      "Epoch 42: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6827 - sparse_categorical_accuracy: 0.5667 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 43/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6769 - sparse_categorical_accuracy: 0.5771\n",
      "Epoch 43: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6769 - sparse_categorical_accuracy: 0.5771 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 44/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6785 - sparse_categorical_accuracy: 0.5813\n",
      "Epoch 44: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6785 - sparse_categorical_accuracy: 0.5813 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 45/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6742 - sparse_categorical_accuracy: 0.5688\n",
      "Epoch 45: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6742 - sparse_categorical_accuracy: 0.5688 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 46/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6726 - sparse_categorical_accuracy: 0.5771\n",
      "Epoch 46: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6726 - sparse_categorical_accuracy: 0.5771 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 47/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6692 - sparse_categorical_accuracy: 0.5437\n",
      "Epoch 47: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6692 - sparse_categorical_accuracy: 0.5437 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 48/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6715 - sparse_categorical_accuracy: 0.5813\n",
      "Epoch 48: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6715 - sparse_categorical_accuracy: 0.5813 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 49/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6663 - sparse_categorical_accuracy: 0.5958\n",
      "Epoch 49: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6663 - sparse_categorical_accuracy: 0.5958 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 50/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6710 - sparse_categorical_accuracy: 0.5875\n",
      "Epoch 50: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6710 - sparse_categorical_accuracy: 0.5875 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 51/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6781 - sparse_categorical_accuracy: 0.5583\n",
      "Epoch 51: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6781 - sparse_categorical_accuracy: 0.5583 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 52/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6722 - sparse_categorical_accuracy: 0.5813\n",
      "Epoch 52: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6722 - sparse_categorical_accuracy: 0.5813 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 53/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6765 - sparse_categorical_accuracy: 0.5500\n",
      "Epoch 53: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6765 - sparse_categorical_accuracy: 0.5500 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 54/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6708 - sparse_categorical_accuracy: 0.5708\n",
      "Epoch 54: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6708 - sparse_categorical_accuracy: 0.5708 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 55/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6739 - sparse_categorical_accuracy: 0.5604\n",
      "Epoch 55: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6739 - sparse_categorical_accuracy: 0.5604 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 56/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6746 - sparse_categorical_accuracy: 0.5625\n",
      "Epoch 56: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6746 - sparse_categorical_accuracy: 0.5625 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 57/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6688 - sparse_categorical_accuracy: 0.5979\n",
      "Epoch 57: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6688 - sparse_categorical_accuracy: 0.5979 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 58/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6713 - sparse_categorical_accuracy: 0.6062\n",
      "Epoch 58: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6713 - sparse_categorical_accuracy: 0.6062 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 59/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6749 - sparse_categorical_accuracy: 0.5604\n",
      "Epoch 59: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6749 - sparse_categorical_accuracy: 0.5604 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 60/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6691 - sparse_categorical_accuracy: 0.5729\n",
      "Epoch 60: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6691 - sparse_categorical_accuracy: 0.5729 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 61/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6756 - sparse_categorical_accuracy: 0.5562\n",
      "Epoch 61: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6756 - sparse_categorical_accuracy: 0.5562 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 62/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6632 - sparse_categorical_accuracy: 0.5979\n",
      "Epoch 62: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6632 - sparse_categorical_accuracy: 0.5979 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 63/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6777 - sparse_categorical_accuracy: 0.5437\n",
      "Epoch 63: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6777 - sparse_categorical_accuracy: 0.5437 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 64/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6732 - sparse_categorical_accuracy: 0.6042\n",
      "Epoch 64: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6732 - sparse_categorical_accuracy: 0.6042 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 65/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6811 - sparse_categorical_accuracy: 0.5521\n",
      "Epoch 65: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6811 - sparse_categorical_accuracy: 0.5521 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 66/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6714 - sparse_categorical_accuracy: 0.5771\n",
      "Epoch 66: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6714 - sparse_categorical_accuracy: 0.5771 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 67/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6740 - sparse_categorical_accuracy: 0.5750\n",
      "Epoch 67: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6740 - sparse_categorical_accuracy: 0.5750 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 68/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6641 - sparse_categorical_accuracy: 0.6333\n",
      "Epoch 68: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6641 - sparse_categorical_accuracy: 0.6333 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 69/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6786 - sparse_categorical_accuracy: 0.5833\n",
      "Epoch 69: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6786 - sparse_categorical_accuracy: 0.5833 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 70/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6658 - sparse_categorical_accuracy: 0.5854\n",
      "Epoch 70: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6658 - sparse_categorical_accuracy: 0.5854 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 71/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6699 - sparse_categorical_accuracy: 0.5813\n",
      "Epoch 71: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6699 - sparse_categorical_accuracy: 0.5813 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 72/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6767 - sparse_categorical_accuracy: 0.5479\n",
      "Epoch 72: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6767 - sparse_categorical_accuracy: 0.5479 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 73/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6770 - sparse_categorical_accuracy: 0.5729\n",
      "Epoch 73: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6770 - sparse_categorical_accuracy: 0.5729 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 74/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6769 - sparse_categorical_accuracy: 0.5792\n",
      "Epoch 74: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6769 - sparse_categorical_accuracy: 0.5792 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 75/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6804 - sparse_categorical_accuracy: 0.5542\n",
      "Epoch 75: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6804 - sparse_categorical_accuracy: 0.5542 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 76/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6680 - sparse_categorical_accuracy: 0.5896\n",
      "Epoch 76: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6680 - sparse_categorical_accuracy: 0.5896 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 77/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6758 - sparse_categorical_accuracy: 0.5729\n",
      "Epoch 77: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6758 - sparse_categorical_accuracy: 0.5729 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 78/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6742 - sparse_categorical_accuracy: 0.5688\n",
      "Epoch 78: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6742 - sparse_categorical_accuracy: 0.5688 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 79/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6800 - sparse_categorical_accuracy: 0.5750\n",
      "Epoch 79: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6800 - sparse_categorical_accuracy: 0.5750 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 80/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6729 - sparse_categorical_accuracy: 0.6021\n",
      "Epoch 80: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6729 - sparse_categorical_accuracy: 0.6021 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 81/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6749 - sparse_categorical_accuracy: 0.5896\n",
      "Epoch 81: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6749 - sparse_categorical_accuracy: 0.5896 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 82/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6770 - sparse_categorical_accuracy: 0.5729\n",
      "Epoch 82: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 345ms/step - loss: 0.6770 - sparse_categorical_accuracy: 0.5729 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 83/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6634 - sparse_categorical_accuracy: 0.5854\n",
      "Epoch 83: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 349ms/step - loss: 0.6634 - sparse_categorical_accuracy: 0.5854 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 84/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6738 - sparse_categorical_accuracy: 0.5917\n",
      "Epoch 84: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 12s 389ms/step - loss: 0.6738 - sparse_categorical_accuracy: 0.5917 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 85/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6737 - sparse_categorical_accuracy: 0.5833\n",
      "Epoch 85: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 11s 374ms/step - loss: 0.6737 - sparse_categorical_accuracy: 0.5833 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 86/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6778 - sparse_categorical_accuracy: 0.5833\n",
      "Epoch 86: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 11s 352ms/step - loss: 0.6778 - sparse_categorical_accuracy: 0.5833 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 87/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6655 - sparse_categorical_accuracy: 0.5771\n",
      "Epoch 87: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6655 - sparse_categorical_accuracy: 0.5771 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 88/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6778 - sparse_categorical_accuracy: 0.5500\n",
      "Epoch 88: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 346ms/step - loss: 0.6778 - sparse_categorical_accuracy: 0.5500 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 89/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6784 - sparse_categorical_accuracy: 0.5646\n",
      "Epoch 89: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6784 - sparse_categorical_accuracy: 0.5646 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 90/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6707 - sparse_categorical_accuracy: 0.5854\n",
      "Epoch 90: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6707 - sparse_categorical_accuracy: 0.5854 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 91/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6732 - sparse_categorical_accuracy: 0.5813\n",
      "Epoch 91: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6732 - sparse_categorical_accuracy: 0.5813 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 92/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6660 - sparse_categorical_accuracy: 0.5979\n",
      "Epoch 92: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6660 - sparse_categorical_accuracy: 0.5979 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 93/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6735 - sparse_categorical_accuracy: 0.5625\n",
      "Epoch 93: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6735 - sparse_categorical_accuracy: 0.5625 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 94/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6837 - sparse_categorical_accuracy: 0.5458\n",
      "Epoch 94: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6837 - sparse_categorical_accuracy: 0.5458 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 95/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6707 - sparse_categorical_accuracy: 0.5854\n",
      "Epoch 95: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6707 - sparse_categorical_accuracy: 0.5854 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 96/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6722 - sparse_categorical_accuracy: 0.5896\n",
      "Epoch 96: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6722 - sparse_categorical_accuracy: 0.5896 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 97/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6800 - sparse_categorical_accuracy: 0.5646\n",
      "Epoch 97: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6800 - sparse_categorical_accuracy: 0.5646 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 98/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6867 - sparse_categorical_accuracy: 0.5542\n",
      "Epoch 98: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6867 - sparse_categorical_accuracy: 0.5542 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 99/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6761 - sparse_categorical_accuracy: 0.5667\n",
      "Epoch 99: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6761 - sparse_categorical_accuracy: 0.5667 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 100/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6726 - sparse_categorical_accuracy: 0.5792\n",
      "Epoch 100: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6726 - sparse_categorical_accuracy: 0.5792 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 101/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6705 - sparse_categorical_accuracy: 0.5813\n",
      "Epoch 101: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6705 - sparse_categorical_accuracy: 0.5813 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 102/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6769 - sparse_categorical_accuracy: 0.5500\n",
      "Epoch 102: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6769 - sparse_categorical_accuracy: 0.5500 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 103/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6726 - sparse_categorical_accuracy: 0.5646\n",
      "Epoch 103: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6726 - sparse_categorical_accuracy: 0.5646 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 104/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6741 - sparse_categorical_accuracy: 0.5708\n",
      "Epoch 104: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6741 - sparse_categorical_accuracy: 0.5708 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 105/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6665 - sparse_categorical_accuracy: 0.5938\n",
      "Epoch 105: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6665 - sparse_categorical_accuracy: 0.5938 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 106/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6737 - sparse_categorical_accuracy: 0.5708\n",
      "Epoch 106: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6737 - sparse_categorical_accuracy: 0.5708 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 107/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6759 - sparse_categorical_accuracy: 0.5813\n",
      "Epoch 107: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6759 - sparse_categorical_accuracy: 0.5813 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 108/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6716 - sparse_categorical_accuracy: 0.5938\n",
      "Epoch 108: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6716 - sparse_categorical_accuracy: 0.5938 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 109/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6792 - sparse_categorical_accuracy: 0.5625\n",
      "Epoch 109: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 348ms/step - loss: 0.6792 - sparse_categorical_accuracy: 0.5625 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 110/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6754 - sparse_categorical_accuracy: 0.5792\n",
      "Epoch 110: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6754 - sparse_categorical_accuracy: 0.5792 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 111/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6738 - sparse_categorical_accuracy: 0.5542\n",
      "Epoch 111: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6738 - sparse_categorical_accuracy: 0.5542 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 112/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6789 - sparse_categorical_accuracy: 0.5688\n",
      "Epoch 112: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6789 - sparse_categorical_accuracy: 0.5688 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 113/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6667 - sparse_categorical_accuracy: 0.5813\n",
      "Epoch 113: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6667 - sparse_categorical_accuracy: 0.5813 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 114/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6906 - sparse_categorical_accuracy: 0.5125\n",
      "Epoch 114: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 348ms/step - loss: 0.6906 - sparse_categorical_accuracy: 0.5125 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 115/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6780 - sparse_categorical_accuracy: 0.5625\n",
      "Epoch 115: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6780 - sparse_categorical_accuracy: 0.5625 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 116/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6786 - sparse_categorical_accuracy: 0.5708\n",
      "Epoch 116: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6786 - sparse_categorical_accuracy: 0.5708 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 117/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6676 - sparse_categorical_accuracy: 0.5875\n",
      "Epoch 117: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6676 - sparse_categorical_accuracy: 0.5875 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 118/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6644 - sparse_categorical_accuracy: 0.6104\n",
      "Epoch 118: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6644 - sparse_categorical_accuracy: 0.6104 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 119/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6725 - sparse_categorical_accuracy: 0.5667\n",
      "Epoch 119: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6725 - sparse_categorical_accuracy: 0.5667 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 120/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6657 - sparse_categorical_accuracy: 0.5958\n",
      "Epoch 120: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6657 - sparse_categorical_accuracy: 0.5958 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 121/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6655 - sparse_categorical_accuracy: 0.6125\n",
      "Epoch 121: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 348ms/step - loss: 0.6655 - sparse_categorical_accuracy: 0.6125 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 122/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6772 - sparse_categorical_accuracy: 0.5771\n",
      "Epoch 122: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6772 - sparse_categorical_accuracy: 0.5771 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 123/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6740 - sparse_categorical_accuracy: 0.5896\n",
      "Epoch 123: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 348ms/step - loss: 0.6740 - sparse_categorical_accuracy: 0.5896 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 124/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6739 - sparse_categorical_accuracy: 0.5688\n",
      "Epoch 124: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6739 - sparse_categorical_accuracy: 0.5688 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 125/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6779 - sparse_categorical_accuracy: 0.5604\n",
      "Epoch 125: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6779 - sparse_categorical_accuracy: 0.5604 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 126/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6738 - sparse_categorical_accuracy: 0.5917\n",
      "Epoch 126: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6738 - sparse_categorical_accuracy: 0.5917 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 127/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6695 - sparse_categorical_accuracy: 0.5729\n",
      "Epoch 127: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6695 - sparse_categorical_accuracy: 0.5729 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 128/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6765 - sparse_categorical_accuracy: 0.5792\n",
      "Epoch 128: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6765 - sparse_categorical_accuracy: 0.5792 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 129/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6642 - sparse_categorical_accuracy: 0.5875\n",
      "Epoch 129: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6642 - sparse_categorical_accuracy: 0.5875 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 130/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6729 - sparse_categorical_accuracy: 0.5854\n",
      "Epoch 130: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6729 - sparse_categorical_accuracy: 0.5854 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 131/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6749 - sparse_categorical_accuracy: 0.5604\n",
      "Epoch 131: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6749 - sparse_categorical_accuracy: 0.5604 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 132/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6733 - sparse_categorical_accuracy: 0.5667\n",
      "Epoch 132: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6733 - sparse_categorical_accuracy: 0.5667 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 133/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6735 - sparse_categorical_accuracy: 0.5938\n",
      "Epoch 133: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6735 - sparse_categorical_accuracy: 0.5938 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 134/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6723 - sparse_categorical_accuracy: 0.5938\n",
      "Epoch 134: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6723 - sparse_categorical_accuracy: 0.5938 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 135/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6738 - sparse_categorical_accuracy: 0.5750\n",
      "Epoch 135: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6738 - sparse_categorical_accuracy: 0.5750 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 136/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6711 - sparse_categorical_accuracy: 0.5875\n",
      "Epoch 136: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6711 - sparse_categorical_accuracy: 0.5875 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 137/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6759 - sparse_categorical_accuracy: 0.5729\n",
      "Epoch 137: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 348ms/step - loss: 0.6759 - sparse_categorical_accuracy: 0.5729 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 138/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6671 - sparse_categorical_accuracy: 0.6021\n",
      "Epoch 138: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6671 - sparse_categorical_accuracy: 0.6021 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 139/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6716 - sparse_categorical_accuracy: 0.5854\n",
      "Epoch 139: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6716 - sparse_categorical_accuracy: 0.5854 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 140/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6771 - sparse_categorical_accuracy: 0.5667\n",
      "Epoch 140: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 348ms/step - loss: 0.6771 - sparse_categorical_accuracy: 0.5667 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 141/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6777 - sparse_categorical_accuracy: 0.5667\n",
      "Epoch 141: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6777 - sparse_categorical_accuracy: 0.5667 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 142/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6736 - sparse_categorical_accuracy: 0.5583\n",
      "Epoch 142: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6736 - sparse_categorical_accuracy: 0.5583 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 143/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6806 - sparse_categorical_accuracy: 0.5396\n",
      "Epoch 143: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6806 - sparse_categorical_accuracy: 0.5396 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 144/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6806 - sparse_categorical_accuracy: 0.5333\n",
      "Epoch 144: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6806 - sparse_categorical_accuracy: 0.5333 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 145/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6640 - sparse_categorical_accuracy: 0.6042\n",
      "Epoch 145: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6640 - sparse_categorical_accuracy: 0.6042 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 146/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6777 - sparse_categorical_accuracy: 0.5604\n",
      "Epoch 146: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6777 - sparse_categorical_accuracy: 0.5604 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 147/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6698 - sparse_categorical_accuracy: 0.5667\n",
      "Epoch 147: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 347ms/step - loss: 0.6698 - sparse_categorical_accuracy: 0.5667 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 148/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6710 - sparse_categorical_accuracy: 0.6083\n",
      "Epoch 148: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 348ms/step - loss: 0.6710 - sparse_categorical_accuracy: 0.6083 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 149/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6706 - sparse_categorical_accuracy: 0.5813\n",
      "Epoch 149: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 348ms/step - loss: 0.6706 - sparse_categorical_accuracy: 0.5813 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n",
      "Epoch 150/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6796 - sparse_categorical_accuracy: 0.5521\n",
      "Epoch 150: val_loss did not improve from 0.69483\n",
      "30/30 [==============================] - 10s 348ms/step - loss: 0.6796 - sparse_categorical_accuracy: 0.5521 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.4833 - lr: 1.0000e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x252e54b5fd0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for model, epochs, batch_size in [(model_nno, stance_config.MODEL_NNO_EPOCHS, stance_config.MODEL_NNO_BATCH_SIZE), (model_obj, stance_config.MODEL_OBJ_EPOCHS, stance_config.MODEL_OBJ_BATCH_SIZE)]:\n",
    "    histories[model] = model.fit(\n",
    "        ds_splits[model]['x_train'], \n",
    "        ds_splits[model]['y_train'], \n",
    "        validation_data = (\n",
    "            ds_splits[model]['x_val'],\n",
    "            ds_splits[model]['y_val']\n",
    "        ),\n",
    "        epochs = epochs,\n",
    "        callbacks = model_callbacks[model],\n",
    "        batch_size = batch_size\n",
    "    )\n",
    "    \n",
    "#Finally, load the best weights obtained during the training:\n",
    "model_nno.load_weights(stance_config.MODEL_NNO_CHECKPOINT_FOLDER)\n",
    "model_obj.load_weights(stance_config.MODEL_OBJ_CHECKPOINT_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05685a98-62a8-4c63-ab80-af0cd468cb75",
   "metadata": {},
   "source": [
    "#### Let us inspect the history of the training of both networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3bff3d88-366d-4e7b-8c7b-66fa6edc3196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_history(history: keras.callbacks.History) -> None:\n",
    "    \"\"\"Plots the history of the training of a certain model.\n",
    "\n",
    "    Args:\n",
    "        history (keras.callbacks.History): History of the training of a model.\n",
    "\n",
    "    \"\"\"\n",
    "    train_loss = history.history['loss']\n",
    "    \n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    # Visualize the behavior of the loss\n",
    "    plt.plot(train_loss)\n",
    "    plt.plot(val_loss)\n",
    "    plt.grid()\n",
    "    plt.title('Loss during training')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "09f9ef8a-468a-4493-a77b-6c439165b9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_history(histories[model_nno])\n",
    "display_history(histories[model_obj])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdade68-e0c7-407a-a121-e0de7acb7274",
   "metadata": {},
   "source": [
    "#### From the data we can infer the epoch that allowed the model to generalize better by inspecting the loss on data that it had never seen before (data on the validation set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "09a32785-11b6-4762-8e83-376d0d7c1cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 currently uses the weights that have been determined on epoch 95.\n",
      "Model 2 currently uses the weights that have been determined on epoch 8.\n"
     ]
    }
   ],
   "source": [
    "models = [model_nno, model_obj]\n",
    "for model_idx in range(len(models)):\n",
    "    print(f'Model {model_idx + 1} currently uses the weights that have been determined on epoch {np.argmin(histories[models[model_idx]].history[\"val_loss\"]) + 1}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6c58ca-464f-4eef-9938-48980b34d4b9",
   "metadata": {},
   "source": [
    "#### Small inspection of the performance of the networks:\n",
    "#### Considering we had scarcely any records that could be used to train our data, we don't expect good performances. We just aim to be, at least, better than a random classifier. Furthermore, the distribution of the classes is heavily unbalanced, meaning that it does not resemble an uniform distribution at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0834406e-26ba-43b5-bd77-cbcaec5ea551",
   "metadata": {},
   "source": [
    "#### The following classification reports sum up the performances of the trained networks with respect to the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "beedbb20-faa2-4ff8-b44d-d2315794f334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for the Model 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.56      0.20      0.29        25\n",
      "           2       0.71      0.94      0.81        66\n",
      "\n",
      "    accuracy                           0.70        96\n",
      "   macro avg       0.42      0.38      0.37        96\n",
      "weighted avg       0.63      0.70      0.63        96\n",
      "\n",
      "Classification report for the Model 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.77      0.68        35\n",
      "           1       0.50      0.32      0.39        25\n",
      "\n",
      "    accuracy                           0.58        60\n",
      "   macro avg       0.56      0.55      0.54        60\n",
      "weighted avg       0.57      0.58      0.56        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print(f'Classification report for the Model {i+1}:')    \n",
    "    y_true = ds_splits[models[i]]['y_test']\n",
    "    y_pred = np.argmax(models[i].predict(ds_splits[models[i]]['x_test']).logits,axis=-1)\n",
    "    print(classification_report(y_true, y_pred, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06d82f5-676b-4b3c-a7f0-8484098a3607",
   "metadata": {},
   "source": [
    "#### The averages of the f1-score prove that the model performs slighly better than a random classifier. The performances make sense considering that only few records were available for training and by recalling the distribution of the classes in the provided dataset."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
